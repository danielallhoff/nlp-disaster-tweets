{"cells":[{"cell_type":"markdown","metadata":{},"source":["This is a repository for the Kaggle Challenge in \"Natural Language Processing with Disaster Tweets\". It consists of the prediction if the tweet mentions a real disaster or not.\n","\n","Challenge link: https://www.kaggle.com/competitions/nlp-getting-started/data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ucYmDJTCs5GF","outputId":"ae043ea7-6c11-45ae-cc17-7bb68313dfa1","trusted":true},"outputs":[],"source":["import torch\n","!pip install scikit-learn pandas re tqdm numpy\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Device in use: {device}\")\n","import os\n","import sklearn\n","import pandas\n","import re\n","import tqdm\n","import numpy as np\n","import torch.utils.data as data_utils\n","from tqdm import tqdm\n","!pip install boto3 sentencepiece sacremoses transformers alive-progress\n","from alive_progress import alive_bar\n","import sys\n","sys.stdout.isatty()\n","import boto3\n","import requests\n","import regex\n","import sentencepiece\n","import sacremoses\n","import transformers\n","import random\n","RANDOM_SEED=0\n","np.random.seed(RANDOM_SEED)\n","random.seed(RANDOM_SEED)\n","MODEL_CONFIG=\"bert-base-cased\""]},{"cell_type":"markdown","metadata":{"id":"C3_ZDCUzVVLS"},"source":["In order to add input from kaggle, use:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y_JJrxHqgk5C","trusted":true},"outputs":[],"source":["\n","import numpy as np\n","import pandas as pd\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","train_path=\"/kaggle/input/nlp-data/train.csv\"\n","test_path=\"/kaggle/input/nlp-data/test.csv\"\n","submission_path = \"/kaggle/input/nlp-data/sample_submission.csv\"\n"]},{"cell_type":"markdown","metadata":{"id":"3nCHdkB3VWUo"},"source":["Whenever the jupyter code is used on Google Collab, its possible to load the data from Google Drive with:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OcSiLkrbs2I0","outputId":"c334f871-3559-4e76-c853-23be2bc6c340"},"outputs":[],"source":["from google.colab import drive\n","## Mount google drive\n","drive.mount('/content/drive/')"]},{"cell_type":"markdown","metadata":{},"source":["Unzip the data!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AtiX5C1OtxeJ","outputId":"256a58e2-a280-4469-aeff-bab8b018538e"},"outputs":[],"source":["!unzip /content/drive/MyDrive/Projects/Kaggle-Disaster-Tweets/data/nlp-getting-started.zip\n","train_path=\"train.csv\"\n","test_path=\"test.csv\"\n","submission_path = \"sample_submission.csv\""]},{"cell_type":"markdown","metadata":{"id":"IS0865GGP38-"},"source":["### Load data"]},{"cell_type":"markdown","metadata":{},"source":["The data (training set and testing set) is loaded via a pandas."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VtpNWJ8rP5tz","outputId":"8b0c8b20-117c-4389-f3ef-1386da0cfda5","trusted":true},"outputs":[],"source":["# Load data\n","from sklearn.utils import shuffle\n","\n","df_train = pandas.read_csv(train_path)\n","df_test = pandas.read_csv(test_path)\n","df_test[\"target\"] = 0\n","print(f\"Number of samples for training: {len(df_train)}\")\n","print(f\"Number of samples for testing: {len(df_test)}\")\n","print(\"Training data structure:\")\n","print(df_train.keys())\n","print(df_train.head())"]},{"cell_type":"markdown","metadata":{"id":"WYnUMwz8MwHM"},"source":["# ChatGPT prompting"]},{"cell_type":"markdown","metadata":{},"source":["Because this problem is a NLP classification problem, we can make use of ChatGPT in order to make the classification. In order to do so, we require to make specific prompts and give context to ChatGPT for identifying if the text talks about a disaster or not."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DxDU9deUpjSc"},"outputs":[],"source":["# Normal classification prompt\n","prompt = \"You are a tweet analyst in order to monitor possible emergencies is posted online like accidents (car accidents, airplane accidents, train wrecks or any type of accident), natural disasters (for example: earthquakes, typhoon, tsunamis, storm damage, fire...etc), crimes (like homicides, killings, bombing, terrorism, casualties), war, scandals....etc.  It’s not always clear whether a tweet´s words are actually referring to a disaster that happened or is happening. ANSWER ONLY WITH ONE INT VALUE: 1 (if the tweet speaks about a disaster or emergency) OR 0 (if not)!!!!!. DO NOT ANSWER WITH MORE THAN ONE INT VALUE!!!! TEXT: {query} YOUR RESPONSE: \"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N-uQzK14NEAN"},"outputs":[],"source":["# Few shot learning prompt\n","prompt = \"You are a tweet analyst in order to monitor possible emergencies is posted online like fire, car or airplane accidents, earthquakes, tsunamis, homicides, bombing, war, storm damage....etc.  It’s not always clear whether a tweet´s words are actually referring to a disaster that happened or is happening. ANSWER ONLY WITH ONE INT VALUE: 1 (if the tweet speaks about a disaster) OR 0 (if not)!!!!!. DO NOT ANSWER WITH MORE THAN ONE INT VALUE!!!! TEXT: On plus side LOOK AT THE SKY LAST NIGHT IT WAS ABLAZE. DISASTER: 0. TEXT: Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all. DISASTER:1. TEXT: I'm on top of the hill and I can see a fire in the woods... DISASTER: 1 TEXT: Jays rocking #MLB @JoeyBats19 just bombed one out of Rogers Centre. Play-offs r ahead for The #BlueJays - Bell Moseby and Barfield r back! DISASTER: 0 TEXT: {query} DISASTER: \"\n"]},{"cell_type":"markdown","metadata":{},"source":["Use openai library and pass key for making calls to ChatGPT with a specific prompt."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2aU5U897MzOR","outputId":"31c26bda-45d3-48f5-f190-396fc50aa6b1"},"outputs":[],"source":["!pip install openai cohere tiktoken\n","import openai\n","import csv\n","openai.api_key = \"KEY\"  # https://platform.openai.com/account/api-keys\n","\n","\n","fieldnames = [\"id\",\"text\", \"pred\"]\n","\n","while True:\n","  csv_filename = 'drive/MyDrive/chat_gpt_predictions.csv'\n","  predictions = []\n","  if os.path.exists(csv_filename):\n","      predictions = pandas.read_csv(csv_filename, index_col=0)\n","      predictions = predictions.index\n","  else:\n","      with open(csv_filename, 'w') as csvfile:\n","        fieldnames = [\"id\",\"text\", \"pred\"]\n","        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n","        writer.writeheader()\n","\n","  try:\n","    with open(csv_filename, 'a') as csvfile:\n","        fieldnames = [\"id\",\"text\", \"pred\"]\n","        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n","        with alive_bar(int(len(df_test)-len(predictions)), force_tty=True) as bar:\n","          for index, row in df_test.iterrows():\n","              bar()\n","              index = df_test.loc[index,\"id\"]\n","              if index in predictions:\n","                continue\n","              content = prompt.format(query=row[\"text\"])\n","\n","              messages = [{\"role\": \"system\",\n","                  \"content\": \"You are an useful tweet analysist.\"}, {\"role\": \"user\", \"content\": content}]\n","\n","              response = openai.ChatCompletion.create(\n","                  model=\"gpt-3.5-turbo\", messages=messages, max_tokens=1)  #  Max tokens to 1 for just one token response\n","\n","              response_content = response.choices[0].message.content\n","              writer.writerow({\"id\":index, \"text\":row[\"text\"], \"pred\":response_content})\n","          break\n","  except Exception as exception:\n","    print(exception)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LjkCrpy9w5rD","outputId":"5763d4e8-b4f9-49c0-9020-310dcc92fcb7"},"outputs":[],"source":["# Submission\n","chat_gpt_preds = pandas.read_csv(\"chat_gpt_predictions.csv\", index_col=0)\n","df_submission = pandas.read_csv(submission_path, index_col=0)\n","df_submission.loc[chat_gpt_preds.index, \"target\"] = chat_gpt_preds[\"pred\"].apply(float).apply(int)\n","df_submission.to_csv(\"submission.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PcTivmejzIlU"},"outputs":[],"source":["# TODO: Test with google bard or another LLM"]},{"cell_type":"markdown","metadata":{"id":"hGLtdn-EtbYO"},"source":["# Data Preprocessing\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Its important to shuffle the data so that the training algorithm does not see consecutive similar data:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NAPYtf47dctf","trusted":true},"outputs":[],"source":["df_train = shuffle(df_train, random_state=RANDOM_SEED)"]},{"cell_type":"markdown","metadata":{"id":"b59rZtNvZ8qk"},"source":["### Data augmentation"]},{"cell_type":"markdown","metadata":{},"source":["In order to add more variety to the data and avoid overfitting and more generalization, its possible to apply data augmentation. In this case, because we are handling text, the NLPAug library is used. With this library, multiple operations can be applied over text: Translation to another language and back to the original language, replace the text with synonims or antonyms, add lexical or gramatical errors...etc."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3mg3JL7JZ4cn"},"outputs":[],"source":["!pip install nlpaug\n","import nlpaug.flow as naf\n","import nlpaug.augmenter.word as naw\n","\n","flow = naf.Sequential([\n","    naw.BackTranslationAug(device=\"cuda\"),\n","    naw.SynonymAug(aug_p=0.3)\n","])\n","\n","print(f\"Number of samples for training before aug: {len(df_train)}\")\n","percent_samples_aug = 0.2\n","print(int(len(df_train) * percent_samples_aug))\n","df_aug = df_train.iloc[0:int(len(df_train) * percent_samples_aug), :].copy()\n","for text_idx in tqdm(range(len(df_aug[\"text\"]))):\n","  text = df_aug.iloc[text_idx][\"text\"]\n","  aug_text = flow.augment(text)\n","  df_aug.iloc[text_idx][\"text\"] = aug_text\n","\n","print(f\"Number of samples for training after aug: {len(df_train)}\")\n","\n","df_aug.to_csv(\"train_aug.csv\", index=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QDoWHbZ4xf3M"},"outputs":[],"source":["df_aug = pandas.read_csv(\"train_aug.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c01dYG4NcjPy"},"outputs":[],"source":["df_train = pandas.concat([df_train, df_aug], ignore_index=True)\n","df_train = shuffle(df_train, random_state=RANDOM_SEED)"]},{"cell_type":"markdown","metadata":{"id":"yEMN0hDG_LHQ"},"source":["### Self-made preprocessing"]},{"cell_type":"markdown","metadata":{},"source":["**IN PROGRESS**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yn9hbZU_sjgf"},"outputs":[],"source":["## Data preprocessing\n","def df_text_preprocessing(df):\n","  sentences = [re.sub(\"[@#'.,!?-]\", '', text.lower()) for text in df[\"text\"]]\n","  print(sentences[0:5])\n","  words = [list(set(\" \".join(sentence))) for sentence in sentences]\n","  df[\"words\"] = words\n","  return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U-SjyQsq4EPb"},"outputs":[],"source":["df_train = df_text_preprocessing(df_train)\n","print(df_train[\"words\"][2])\n","print(df_train[\"text\"][2])"]},{"cell_type":"markdown","metadata":{"id":"MZ5Y4Ths_Cfe"},"source":["### Preprocessing BERT with Hugginface\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["One option for doing NLP Classification (or any general AI task), is to finetune a large and generic model to a specific task like this. BERT is one of these large models. It was as \"Pre-training of Deep Bidirectional Transformers for Language Understanding\". On one side, its possible to encode the texts and finetune these encodings with Machine Learning Algorithms. On the other side, you can finetune the whole Transformer with the specific data. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sM_JPxRfA0-e","trusted":true},"outputs":[],"source":["from transformers import BertModel, BertTokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PmaSQTuK_9qY","trusted":true},"outputs":[],"source":["def df_tokenize_bert(texts, tokenizer, max_length=None):\n","  if max_length is None:\n","    max_length_info = max([len(str(text)) for text in texts])\n","    print(f\"Max length info of: {max_length_info}\")\n","    max_length = max_length_info\n","  attention_mask = [[1 if idx < len(str(text)) else 0 for idx in range(max_length)] for text in texts]\n","  tokens =[]\n","  attention_mask = []\n","  # TODO: use batch_encode_plus for faster extraction\n","  for text in texts:\n","    encoding = tokenizer.encode_plus(str(text), add_special_tokens=True,max_length=max_length,padding='max_length')\n","    tokens.append(encoding.input_ids)\n","    attention_mask.append(encoding.attention_mask)\n","\n","  return np.int32(tokens), np.array(attention_mask, dtype=bool), max_length"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XShQ0xWO_HLL","trusted":true},"outputs":[],"source":["def df_predict_encodings(tokens, attention_mask, targets, model, batch_size=8, output_layer=\"pooler_output\"):\n","  tokens_tensor = data_utils.TensorDataset(torch.tensor(tokens), torch.ByteTensor(attention_mask),torch.IntTensor(targets))\n","  predict_loader = data_utils.DataLoader(dataset = tokens_tensor, batch_size = batch_size, shuffle = False)  # For preprocessing\n","  encodings = []\n","  model = model.to(device)\n","  with alive_bar(int(len(tokens)/batch_size)) as bar:\n","    with torch.no_grad():\n","      for texts, attention_mask, _ in predict_loader:\n","        texts = texts.to(device)\n","        attention_mask = attention_mask.to(device)\n","        encodings_batch = model(texts, attention_mask)\n","        encodings_batch = getattr(encodings_batch, output_layer).cpu() # Get encodings\n","        encodings.extend(np.float32(encodings_batch))\n","        bar()\n","\n","\n","  return np.float32(encodings)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9WSdwImUxXOs","trusted":true},"outputs":[],"source":["def load_bert_encodings(df, key=\"text\", max_length=None, model_config=\"bert-base-uncased\", batch_size=256, output_layer=\"pooler_output\"):\n","  tokenizer = BertTokenizer.from_pretrained(model_config)\n","  model = BertModel.from_pretrained(model_config)\n","  tokens, attention_mask, max_length = df_tokenize_bert(df[key], tokenizer, max_length=max_length)\n","  print(f\"Length tokens in use {len(tokens[0])}\")\n","  encodings = df_predict_encodings(tokens, attention_mask, df[\"target\"], model, batch_size, output_layer)\n","  print(f\"Number of encondings: {len(encodings)}\")\n","  print(f\"Encondings shape: {encodings.shape}\")\n","  return encodings, max_length"]},{"cell_type":"markdown","metadata":{},"source":["Load the training encodings!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":390,"referenced_widgets":["4e920f7f3c734607a08d09f595f5c3fd","97d69ea476104ed694b5ee43ba31fda8","2c99f54f5fa64ce2b370d278bd23d6b4","9a0c5228cd0e4445993ce38b8f6475c4","bb7cfdae2f5441efad85b6b3afd662b9","0dae2ee73e29401ba958bcccae544244","43ac619cc5da46d8830319eab4ea963e","bd42f1137f36470b9ce0758e74828033","cc7446868b67422490db8da98f0d1959","abc0a2c42e414c31b9204a1be04872d8","8199b97ce31c477386ff7283e91faab2","96dcaa13fe08427ebbf9833b94f8bca0","d87cea50bf0d4998b6a96e4c16bfd216","a5a04787ace84387bdf787872e190ee7","c9a82d7bc3754aed8f13d71ab062f584","8e0613df061d42c8892f98384bd3acf5","6110f822285a4f7796ffe8a52fc0bad3","ae7dfcc4a9194ad598c503753f444a70","6205088a637143a7a45a583c5aaeeca6","e463b10e0177452980ba176467fcc55f","b93b1e8857f34aa6b248b392786932e4","c5cf27d1831249f2a932eae772f33223","a3ce10dad6424a0e8d635dddef8238a5","802251738ecf4d1bbd72f9925f5bdc99","1b2ad0939b6342d7a60916fb69282926","8265228880a0486696d05e7700e18119","7da04c0a806141da99128528a24d00ad","63b2386898244000a6cc2f5284f777f0","e637ebe0661d4394b76ef4ebde351c50","8a5ad34232be4b47842010cfc0fb1240","507ce30ba7d7478ca62fdb1ab13dca77","900b11fe2af84ce990ef889e53ff72f8","450ca49c401c4a78a108d33b7bb40324","e848258434a74beaba4d019540f67e70","07df399d73c54a0bb5a0dab9912f6cf3","a778b4c6c36c4ced9b3ab502674e90f9","6d8e643ce35f42d0a0649e5c59b55c58","2214e3a7f1a740a4a1d02c8a2e0c29e1","2f726af9fe284240a5ce603d61915bbd","4c826a4c1dec4a46b203f3fe406722e1","21426b284f724494bd3234ca686d2e83","72ef41024ac642079585b918995a9aec","10d61f577468435996d83f7c2a1e7209","0de808a61ec74ad1810cd5a99a823f88","0fb9a6bead67421288ccc2bbaa8d71b9","f2bf07fd4ba645728389d950254b6f99","76d88b677e9e42cf834385aa81dc7670","d928324fbf114a498376ba1a9b9e43fb","6df1dd10be6841b4ad3e2ca2a9732259","dbd1cb60999d4321b79e8f66e284c2ae","d23ec24d734f4f69823e8e6362d63fee","07cd94b820a645359f0fa351949c7026","dc5f4d33155a4a078f7c62d1fc44149e","aa0a3e5aee704f14a8886c9494bbbf57","64a7cdb5f00c40b1942f5097e313a1a3"]},"id":"ixyqtc0kqabO","outputId":"484726c0-85f8-4279-bff4-e50e9a1b2aed","trusted":true},"outputs":[],"source":["# Bert encodings\n","X_train, max_length = load_bert_encodings(df_train, key=\"text\", max_length=300, model_config=MODEL_CONFIG, batch_size=256, output_layer=\"pooler_output\")\n","Y_train = df_train[\"target\"]"]},{"cell_type":"markdown","metadata":{},"source":["Another useful feature from the training data is the keyword. This keyword can also be encoded and used."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8W9IwxnJyPgO","outputId":"abb720c7-9ea7-464c-d7f6-0562479a1951","trusted":true},"outputs":[],"source":["X_train_keyword, max_length = load_bert_encodings(df_train, key=\"keyword\", max_length=300, model_config=MODEL_CONFIG, batch_size=256, output_layer=\"pooler_output\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MIl-UF_Hnzm5","outputId":"7ac7ae98-817e-4858-ed11-458c3aa6449a","trusted":true},"outputs":[],"source":["X_test, _ = load_bert_encodings(df_test, max_length=max_length, model_config=MODEL_CONFIG, batch_size=32, output_layer=\"pooler_output\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yqIH0O7DynTJ","outputId":"342c7349-1089-4da6-f768-f47c2400314c","trusted":true},"outputs":[],"source":["X_test_keyword, _ = load_bert_encodings(df_test, key=\"keyword\",max_length=max_length, model_config=MODEL_CONFIG, batch_size=32, output_layer=\"pooler_output\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Kz0lvSkgk5G","trusted":true},"outputs":[],"source":["X_train_features = X_train.copy()\n","X_train_keyword_features = X_train_keyword.copy()\n","X_test_features = X_test.copy()\n","X_test_keyword_features = X_test_keyword.copy()\n","Y_train_features = Y_train.copy()"]},{"cell_type":"markdown","metadata":{"id":"_7NSMPwjyxey"},"source":["#### Join text and keyword features"]},{"cell_type":"markdown","metadata":{},"source":["Join these features into one encoding!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OtMMXXGMpTzo","outputId":"7a07e5e4-87da-4c94-ea70-defd3cfe3c68","trusted":true},"outputs":[],"source":["print(f\"X_train shape before: {X_train_features.shape}\")\n","X_train_features = np.concatenate((X_train_features, X_train_keyword_features), axis=-1)\n","X_test_features = np.concatenate((X_test_features, X_test_keyword_features), axis=-1)\n","print(f\"X_train shape after: {X_train_features.shape}\")"]},{"cell_type":"markdown","metadata":{"id":"n3kQZtFXyN8m"},"source":["## Train and val split"]},{"cell_type":"markdown","metadata":{},"source":["In every machine learning problem, data is splitted into a training set and testing set. Moreover, it can exist a specific validation set which is used as a previous step to evaluate the testing set. For example, the validation set in deep learning can be used for early stopping (stop training when the model does not improve over the validation set)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d5Nsu4LlyPyw","trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","NUM_SAMPLES_VALIDATION = 500\n","X_val_split = X_train_features[0:NUM_SAMPLES_VALIDATION]\n","Y_val_split = Y_train_features[0:NUM_SAMPLES_VALIDATION]\n","X_train_split = X_train_features[NUM_SAMPLES_VALIDATION:]\n","Y_train_split = Y_train_features[NUM_SAMPLES_VALIDATION:]\n","# X_train_split, X_val_split, Y_train_split, Y_val_split = train_test_split(X_train, Y_train, test_size=0.10, random_state=RANDOM_SEED)"]},{"cell_type":"markdown","metadata":{"id":"O0FaJtSuPNxG"},"source":["# Finetuning"]},{"cell_type":"markdown","metadata":{"id":"Vwt5F0tGZD-M"},"source":["## SMOTE, RandomUnderSampler...etc"]},{"cell_type":"markdown","metadata":{},"source":["The SMOTE technique helps to augment synthetically the unrepresented class of the training set. The synthetic data is created by creating intermediate representations of the real existing data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5WGMBjFyZGjS","trusted":true},"outputs":[],"source":["from imblearn.over_sampling import SMOTE\n","from imblearn.under_sampling import RandomUnderSampler\n","from imblearn.pipeline import Pipeline\n","sampling_strategy = \"over\"\n","\n","if sampling_strategy == \"over\":\n","  pipeline = SMOTE(random_state=RANDOM_SEED)\n","elif sampling_strategy == \"under\":\n","  pipeline = RandomUnderSampler(sampling_strategy=\"majority\", random_state=RANDOM_SEED)\n","elif sampling_strategy == \"both\":\n","  over = SMOTE(sampling_strategy=0.85, random_state=RANDOM_SEED)\n","  under = RandomUnderSampler(sampling_strategy=\"majority\", random_state=RANDOM_SEED)\n","\n","  steps = [('o', over), ('u', under)]\n","  pipeline = Pipeline(steps=steps)\n","\n","X_train_split, Y_train_split = pipeline.fit_resample(X_train_split, Y_train_split)"]},{"cell_type":"markdown","metadata":{"id":"YTHcFadJ0D7D"},"source":["## PCA"]},{"cell_type":"markdown","metadata":{},"source":["Principal Component Analysis (PCA) can be useful to reduce the high dimensions of the features by keeping the most relevant ones (the features which has less correlation between the rest and more variety)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4b3KZayk0GL9","trusted":true},"outputs":[],"source":["from sklearn.decomposition import PCA\n","pca = PCA(n_components=64)\n","pca.fit(X_train_split)\n","X_train_split = pca.transform(X_train_split)\n","X_val_split = pca.transform(X_val_split)\n","X_test_features = pca.transform(X_test_features)"]},{"cell_type":"markdown","metadata":{"id":"TGk9QZJMwnws"},"source":["## SVM"]},{"cell_type":"markdown","metadata":{},"source":["Support Vector Machines (SVM) is one of the most used machine learning classification algorithms."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DCTbT0-_PPuC"},"outputs":[],"source":["from sklearn import svm\n","\n","clf = svm.SVC()\n","clf.fit(X_train_split, Y_train_split)\n","\n","Y_pred = clf.predict(X_val_split)\n","Y_test_pred = clf.predict(X_test_features)"]},{"cell_type":"markdown","metadata":{"id":"bJ2oTh1Sn-bR"},"source":["## KNN\n"]},{"cell_type":"markdown","metadata":{},"source":["K-Nearest Neighbors (KNN) is a classification algorithm which checks the K most nearest neighbors of a specific data point in order to find the most probable class it represents. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MMWNpRVAoC2z"},"outputs":[],"source":["from sklearn.neighbors import KNeighborsClassifier\n","knn_classifier = KNeighborsClassifier(n_neighbors=3)\n","knn_classifier.fit(X_train_split, Y_train_split)\n","\n","Y_pred = knn_classifier.predict(X_val_split)\n","Y_test_pred = knn_classifier.predict(X_test_features)"]},{"cell_type":"markdown","metadata":{"id":"XDMCMZLdYnta"},"source":["## Random forests"]},{"cell_type":"markdown","metadata":{},"source":["Random forests creates a big decission tree of the data automatically for classification."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UM2Z2cUFYpJs","outputId":"4ae27514-c0ff-4209-b177-319ecc2048d3","trusted":true},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n","\n","clf = RandomForestClassifier()\n","clf.fit(X_train_split, Y_train_split)\n","\n","Y_pred = clf.predict(X_val_split)\n","Y_test_pred = clf.predict(X_test_features)"]},{"cell_type":"markdown","metadata":{"id":"VE9rj1dJtaEY"},"source":["# Networks"]},{"cell_type":"markdown","metadata":{"id":"BeW__EVPKOZS"},"source":["## MLPClassifier\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["The Multi-Layer Perceptron (MLP) learns the best weights in order to fit the data with a loss function."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6pBkkqEyPNKA","outputId":"51f5ae6a-a674-487d-e978-5516cd5623b0"},"outputs":[],"source":["from sklearn.neural_network import MLPClassifier\n","\n","clf = MLPClassifier(random_state=RANDOM_SEED, max_iter=1000, activation=\"logistic\",learning_rate=\"adaptive\", batch_size=128, early_stopping=True, verbose=True, n_iter_no_change=200)\n","clf.fit(X_train_split, Y_train_split)\n","Y_pred = clf.predict(X_val_split)\n","Y_test_pred = clf.predict(X_test_features)"]},{"cell_type":"markdown","metadata":{"id":"fXLdrr1wtd2i"},"source":["## BERT Finetuning"]},{"cell_type":"markdown","metadata":{"id":"0KdALxRlRRVH"},"source":["### Custom Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"clKioR0xTEyi","trusted":true},"outputs":[],"source":["MAX_LEN = 200\n","TRAIN_BATCH_SIZE = 8\n","VALID_BATCH_SIZE = 4\n","EPOCHS = 30\n","LEARNING_RATE = 1e-05"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kqQovMQdRS0A","trusted":true},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n","from sklearn.utils.class_weight import compute_class_weight\n","class CustomDataset(Dataset):\n","\n","    def __init__(self, dataframe, tokenizer, max_len, class_weights=False):\n","        self.tokenizer = tokenizer\n","        self.data = dataframe\n","        self.text = dataframe.text\n","        self.idxs = dataframe.index\n","        self.targets = self.data.target\n","        self.max_len = max_len\n","        self.class_weights = class_weights\n","        self.weights_per_class = compute_class_weight(class_weight=\"balanced\",y=self.targets, classes=np.unique(self.targets))\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        idx = self.idxs[index]\n","        text = str(self.text[idx])\n","        text = \" \".join(text.split())\n","\n","        inputs = self.tokenizer.encode_plus(\n","            text,\n","            None,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            pad_to_max_length=True,\n","            return_token_type_ids=True\n","        )\n","        ids = inputs['input_ids']\n","        mask = inputs['attention_mask']\n","        token_type_ids = inputs[\"token_type_ids\"]\n","        weight = torch.tensor(self.weights_per_class[self.targets[idx]], dtype=torch.float)\n","        targets = torch.tensor([self.targets[idx]], dtype=torch.float)\n","        return {\n","            'ids': torch.tensor(ids, dtype=torch.long),\n","            'mask': torch.tensor(mask, dtype=torch.long),\n","            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n","            'targets': targets,\n","            'weight': weight\n","        }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RQpzC6CCtZ6Q","trusted":true},"outputs":[],"source":["from transformers import BertModel, BertTokenizer\n","tokenizer = BertTokenizer.from_pretrained(MODEL_CONFIG)\n","new_df = df_train[['text', 'target']].copy()\n","NUM_SAMPLES_VALIDATION = 500\n","\n","training_df = new_df[NUM_SAMPLES_VALIDATION:]\n","validation_df = new_df[0: NUM_SAMPLES_VALIDATION]\n","\n","training_loader = CustomDataset(training_df, tokenizer, max_len=MAX_LEN)\n","validation_loader = CustomDataset(validation_df, tokenizer, max_len=MAX_LEN)\n","\n","train_params = {'batch_size': TRAIN_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 0\n","                }\n","valid_params = {'batch_size': VALID_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 0\n","                }\n","\n","training_loader = DataLoader(training_loader, **train_params)\n","validation_loader = DataLoader(validation_loader, **valid_params)\n"]},{"cell_type":"markdown","metadata":{"id":"v4e3aH5rT-GG"},"source":["### Model definition"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UaF2SydmStG8","trusted":true},"outputs":[],"source":["class BERTClass(torch.nn.Module):\n","    def __init__(self, model):\n","        super(BERTClass, self).__init__()\n","        self.l1 = model\n","        self.l2 = torch.nn.Dropout(0.3)\n","        self.l3 = torch.nn.Linear(768,64)\n","        self.l4 = torch.nn.Linear(64,1)\n","\n","    def forward(self, ids, mask, token_type_ids):\n","        _, output_1= self.l1(input_ids=ids, attention_mask = mask, token_type_ids = token_type_ids, return_dict=False)\n","        output_2 = self.l2(output_1)\n","        output_3 = self.l3(output_2)\n","        output = self.l4(output_3)\n","        activation = torch.sigmoid(output)\n","        return activation\n","\n","model = BERTClass(model=BertModel.from_pretrained(MODEL_CONFIG))\n","model.to(device)"]},{"cell_type":"markdown","metadata":{"id":"dpoFiG45T_wg"},"source":["### Training Loop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T5t7aY6fUBBi","trusted":true},"outputs":[],"source":["def loss_fn(outputs, targets,weights=None):\n","    losses = torch.nn.BCELoss(reduction='none')(outputs, targets, )\n","    return torch.mean(weights*losses)\n","optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LpelyYevUI85","trusted":true},"outputs":[],"source":["def forward(data, model):\n","    ids = data['ids'].to(device, dtype = torch.long)\n","    mask = data['mask'].to(device, dtype = torch.long)\n","    token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","    targets = data['targets'].to(device, dtype = torch.float)\n","    weights = data['weight'].to(device, dtype = torch.float)\n","    outputs = model(ids, mask, token_type_ids)\n","    optimizer.zero_grad()\n","    loss = loss_fn(outputs, targets,weights)\n","    return loss\n","\n","def train(epochs, model, training_loader, validation_loader, early_stopping=False, n_iter_no_change=5):\n","    MIN_VAL_LOSS = 100000000\n","    best_model = model\n","    n_iter_no_change_count = 0\n","    for epoch in range(epochs):\n","      model.train()\n","      total_loss = 0\n","      num_iterations = 1\n","      for _,data in enumerate(training_loader, 0):\n","          optimizer.zero_grad()\n","          loss = forward(data, model)\n","          total_loss += loss.item()\n","          print(f'Epoch: {epoch}, Loss:  {total_loss/num_iterations}')\n","          num_iterations += 1\n","          optimizer.zero_grad()\n","          loss.backward()\n","          optimizer.step()\n","      if early_stopping:\n","        total_val_loss = 0\n","        num_val_iterations = 1\n","        print(\"Validating...\")\n","        for _, data in enumerate(validation_loader, 0):\n","            val_loss = forward(data, model)\n","            total_val_loss += val_loss.item()\n","            num_val_iterations += 1\n","        val_loss = total_val_loss/num_val_iterations\n","        print(f\"Val_loss: {val_loss}, MIN_VAL_LOSS: {MIN_VAL_LOSS}\")\n","        if val_loss < MIN_VAL_LOSS:\n","            MIN_VAL_LOSS = val_loss\n","            n_iter_no_change_count = 0\n","            print(f\"Validation loss has improved to {val_loss}!\")\n","            torch.save(model.state_dict(), \"bert_finetuned\")\n","            best_model = model\n","        else:\n","          n_iter_no_change_count += 1\n","        print(f'Epoch: {epoch}, Loss:  {total_loss/num_iterations}, Validation loss: {val_loss}')\n","        if n_iter_no_change_count >= n_iter_no_change:\n","            return best_model\n","    return best_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LEDszHr7Wvca","trusted":true},"outputs":[],"source":["model = train(EPOCHS, model, training_loader, validation_loader, early_stopping=True, n_iter_no_change=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fMvv84NrXxEP","trusted":true},"outputs":[],"source":["testing_loader = CustomDataset(df_test, tokenizer, max_len=MAX_LEN)\n","test_params = {'batch_size': VALID_BATCH_SIZE,\n","                'shuffle': False,\n","                'num_workers': 0\n","                }\n","testing_loader = DataLoader(testing_loader, **test_params)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IefxnOPjXvJs","trusted":true},"outputs":[],"source":["def predict(model, testing_loader):\n","    fin_outputs=[]\n","    with torch.no_grad():\n","        for _, data in enumerate(testing_loader, 0):\n","            ids = data['ids'].to(device, dtype = torch.long)\n","            mask = data['mask'].to(device, dtype = torch.long)\n","            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","            targets = data['targets'].to(device, dtype = torch.float)\n","            outputs = model(ids, mask, token_type_ids)\n","            fin_outputs.extend((outputs.cpu().detach().numpy() > 0.5)[:,0].astype(int).tolist() )\n","    return fin_outputs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GeD7aAMOYLoX","trusted":true},"outputs":[],"source":["Y_pred_test = predict(model, testing_loader)"]},{"cell_type":"markdown","metadata":{"id":"cMzOFQjQ2p5V"},"source":["# Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0JUpd9wy2pnD","trusted":true},"outputs":[],"source":["from sklearn.metrics import precision_recall_fscore_support\n","def eval_test(y_true, y_pred):\n","  precission, recall, fscore, _ = precision_recall_fscore_support(y_true, y_pred, average=\"binary\")\n","  print(f\"Population {len(y_true)}\")\n","  print(f\"F1-score\\t| Precission\\t| Recall\")\n","  print(f\"{(fscore*100).round(2)}%\\t\\t| {(precission*100).round(2)}%\\t| {(recall*100).round(2)}%\")\n","  return precission, recall, fscore"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PXUR_3CVyt-_","outputId":"f2d7d5e6-52c2-4f90-f7be-c4751c4d58f5","trusted":true},"outputs":[],"source":["precission, recall, fscore = eval_test(Y_val_split.values, Y_pred)"]},{"cell_type":"markdown","metadata":{"id":"3uKckY5AW1Fz"},"source":["## Save model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q6TFsAN8W2jO"},"outputs":[],"source":["import pickle\n","pickle.dump(pca, open(\"pca.sav\", 'wb'))\n","# Reload clf\n","# loaded_model = pickle.load(open(\"model.sav\", 'rb'))"]},{"cell_type":"markdown","metadata":{"id":"SRZ4vZB8jp5E"},"source":["## Submit\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PlHkTRjtj7b9","trusted":true},"outputs":[],"source":["df_submission = pandas.read_csv(submission_path)\n","df_submission.loc[:,\"target\"] = Y_pred_test\n","df_submission.to_csv(\"submission.csv\", index=False)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"widgets":{"application/vnd.jupyter.widget-state+json":{"07cd94b820a645359f0fa351949c7026":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07df399d73c54a0bb5a0dab9912f6cf3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f726af9fe284240a5ce603d61915bbd","placeholder":"​","style":"IPY_MODEL_4c826a4c1dec4a46b203f3fe406722e1","value":"Downloading (…)lve/main/config.json: 100%"}},"0dae2ee73e29401ba958bcccae544244":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0de808a61ec74ad1810cd5a99a823f88":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0fb9a6bead67421288ccc2bbaa8d71b9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f2bf07fd4ba645728389d950254b6f99","IPY_MODEL_76d88b677e9e42cf834385aa81dc7670","IPY_MODEL_d928324fbf114a498376ba1a9b9e43fb"],"layout":"IPY_MODEL_6df1dd10be6841b4ad3e2ca2a9732259"}},"10d61f577468435996d83f7c2a1e7209":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b2ad0939b6342d7a60916fb69282926":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a5ad34232be4b47842010cfc0fb1240","max":435797,"min":0,"orientation":"horizontal","style":"IPY_MODEL_507ce30ba7d7478ca62fdb1ab13dca77","value":435797}},"21426b284f724494bd3234ca686d2e83":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2214e3a7f1a740a4a1d02c8a2e0c29e1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c99f54f5fa64ce2b370d278bd23d6b4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd42f1137f36470b9ce0758e74828033","max":29,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cc7446868b67422490db8da98f0d1959","value":29}},"2f726af9fe284240a5ce603d61915bbd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43ac619cc5da46d8830319eab4ea963e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"450ca49c401c4a78a108d33b7bb40324":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c826a4c1dec4a46b203f3fe406722e1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e920f7f3c734607a08d09f595f5c3fd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_97d69ea476104ed694b5ee43ba31fda8","IPY_MODEL_2c99f54f5fa64ce2b370d278bd23d6b4","IPY_MODEL_9a0c5228cd0e4445993ce38b8f6475c4"],"layout":"IPY_MODEL_bb7cfdae2f5441efad85b6b3afd662b9"}},"507ce30ba7d7478ca62fdb1ab13dca77":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6110f822285a4f7796ffe8a52fc0bad3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6205088a637143a7a45a583c5aaeeca6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63b2386898244000a6cc2f5284f777f0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64a7cdb5f00c40b1942f5097e313a1a3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6d8e643ce35f42d0a0649e5c59b55c58":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_10d61f577468435996d83f7c2a1e7209","placeholder":"​","style":"IPY_MODEL_0de808a61ec74ad1810cd5a99a823f88","value":" 570/570 [00:00&lt;00:00, 38.6kB/s]"}},"6df1dd10be6841b4ad3e2ca2a9732259":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72ef41024ac642079585b918995a9aec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"76d88b677e9e42cf834385aa81dc7670":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_07cd94b820a645359f0fa351949c7026","max":435755784,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dc5f4d33155a4a078f7c62d1fc44149e","value":435755784}},"7da04c0a806141da99128528a24d00ad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"802251738ecf4d1bbd72f9925f5bdc99":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_63b2386898244000a6cc2f5284f777f0","placeholder":"​","style":"IPY_MODEL_e637ebe0661d4394b76ef4ebde351c50","value":"Downloading (…)/main/tokenizer.json: 100%"}},"8199b97ce31c477386ff7283e91faab2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8265228880a0486696d05e7700e18119":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_900b11fe2af84ce990ef889e53ff72f8","placeholder":"​","style":"IPY_MODEL_450ca49c401c4a78a108d33b7bb40324","value":" 436k/436k [00:00&lt;00:00, 15.8MB/s]"}},"8a5ad34232be4b47842010cfc0fb1240":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e0613df061d42c8892f98384bd3acf5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"900b11fe2af84ce990ef889e53ff72f8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96dcaa13fe08427ebbf9833b94f8bca0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d87cea50bf0d4998b6a96e4c16bfd216","IPY_MODEL_a5a04787ace84387bdf787872e190ee7","IPY_MODEL_c9a82d7bc3754aed8f13d71ab062f584"],"layout":"IPY_MODEL_8e0613df061d42c8892f98384bd3acf5"}},"97d69ea476104ed694b5ee43ba31fda8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0dae2ee73e29401ba958bcccae544244","placeholder":"​","style":"IPY_MODEL_43ac619cc5da46d8830319eab4ea963e","value":"Downloading (…)okenizer_config.json: 100%"}},"9a0c5228cd0e4445993ce38b8f6475c4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_abc0a2c42e414c31b9204a1be04872d8","placeholder":"​","style":"IPY_MODEL_8199b97ce31c477386ff7283e91faab2","value":" 29.0/29.0 [00:00&lt;00:00, 1.10kB/s]"}},"a3ce10dad6424a0e8d635dddef8238a5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_802251738ecf4d1bbd72f9925f5bdc99","IPY_MODEL_1b2ad0939b6342d7a60916fb69282926","IPY_MODEL_8265228880a0486696d05e7700e18119"],"layout":"IPY_MODEL_7da04c0a806141da99128528a24d00ad"}},"a5a04787ace84387bdf787872e190ee7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6205088a637143a7a45a583c5aaeeca6","max":213450,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e463b10e0177452980ba176467fcc55f","value":213450}},"a778b4c6c36c4ced9b3ab502674e90f9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_21426b284f724494bd3234ca686d2e83","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_72ef41024ac642079585b918995a9aec","value":570}},"aa0a3e5aee704f14a8886c9494bbbf57":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abc0a2c42e414c31b9204a1be04872d8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae7dfcc4a9194ad598c503753f444a70":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b93b1e8857f34aa6b248b392786932e4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb7cfdae2f5441efad85b6b3afd662b9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd42f1137f36470b9ce0758e74828033":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5cf27d1831249f2a932eae772f33223":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c9a82d7bc3754aed8f13d71ab062f584":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b93b1e8857f34aa6b248b392786932e4","placeholder":"​","style":"IPY_MODEL_c5cf27d1831249f2a932eae772f33223","value":" 213k/213k [00:00&lt;00:00, 3.82MB/s]"}},"cc7446868b67422490db8da98f0d1959":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d23ec24d734f4f69823e8e6362d63fee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d87cea50bf0d4998b6a96e4c16bfd216":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6110f822285a4f7796ffe8a52fc0bad3","placeholder":"​","style":"IPY_MODEL_ae7dfcc4a9194ad598c503753f444a70","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"d928324fbf114a498376ba1a9b9e43fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa0a3e5aee704f14a8886c9494bbbf57","placeholder":"​","style":"IPY_MODEL_64a7cdb5f00c40b1942f5097e313a1a3","value":" 436M/436M [00:02&lt;00:00, 241MB/s]"}},"dbd1cb60999d4321b79e8f66e284c2ae":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc5f4d33155a4a078f7c62d1fc44149e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e463b10e0177452980ba176467fcc55f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e637ebe0661d4394b76ef4ebde351c50":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e848258434a74beaba4d019540f67e70":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_07df399d73c54a0bb5a0dab9912f6cf3","IPY_MODEL_a778b4c6c36c4ced9b3ab502674e90f9","IPY_MODEL_6d8e643ce35f42d0a0649e5c59b55c58"],"layout":"IPY_MODEL_2214e3a7f1a740a4a1d02c8a2e0c29e1"}},"f2bf07fd4ba645728389d950254b6f99":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dbd1cb60999d4321b79e8f66e284c2ae","placeholder":"​","style":"IPY_MODEL_d23ec24d734f4f69823e8e6362d63fee","value":"Downloading model.safetensors: 100%"}}}}},"nbformat":4,"nbformat_minor":4}
