# NLP Kaggle Challenge: Disaster Tweets
## Results over validation set
| Experiment    | F1-Score | Precission | Recall
| ------------- | ------------- | ------------- | -------------
| Pretrained BERT + SVM with 768 components | 7.8% | 86.7% | 4.1% 
| Pretrained BERT + Random Forests | 61.4% | 69% | 55.2%
| Pretrained BERT + PCA (2 components) + SVM  | 1.2%  | 33.3% | 0.6% 
| Pretrained BERT + PCA (32 components) + SVM  | 61.5%  | 66.7% | 57.1%
| Pretrained BERT + PCA (64 components) + SVM  | 61.5%  | 68% | 56.2%

**IN PROGRESS**

## Kaggle results
**IN PROGRESS**

## Links
- Torch transformers: https://pytorch.org/hub/huggingface_pytorch-transformers/
- Finetune transformers: https://huggingface.co/transformers/v4.2.2/custom_datasets.html
